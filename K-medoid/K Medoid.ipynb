{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the packages for the execution of the code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining euclidean distance function and passing the testing and training set that are formed after sampling the data frame formed.\n",
    "\n",
    "\n",
    "def eucledian_distance(testing_set,training_set):\n",
    "    distance_euclidean=0     #distance_euclidean will be storing the distance, calculated \n",
    "                             #by iterating the training set using the testing set values row-wise that are being sent \n",
    "                             #one by one once we call the function.'''   \n",
    "    for i in range(len(training_set)):\n",
    "        distance_euclidean=distance_euclidean+np.power((testing_set[i]-training_set[i]),2)\n",
    "        \n",
    "    return np.sqrt(distance_euclidean)    #returning the square rooted value of the calculated distance for a partiular row in both the sets \n",
    "                                          #back to the part of the code where the function is called.The number of values returned\n",
    "                                          #will be equal to the number of rows available in the testing set.''' \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     InpatientDays  ERVisits  OfficeVisits\n",
      "112              2         2            22\n",
      "7                2         0             8\n",
      "    InpatientDays  ERVisits  OfficeVisits\n",
      "13              1         1            20\n",
      "86              1         0             7\n",
      "    InpatientDays  ERVisits  OfficeVisits\n",
      "13              1         1            20\n",
      "86              1         0             7\n"
     ]
    }
   ],
   "source": [
    "effective_dataframe= pd.read_csv(\"quality.csv\")\n",
    "#Creating k Random medoids for k=2\n",
    "k=2\n",
    "sample_kinstances=effective_dataframe.sample(n=k,replace=False)\n",
    "\n",
    "\n",
    "dictionary_conewfinal={}\n",
    "for couter in range(100):\n",
    "    \n",
    "    distance_matrix=[]\n",
    "    dictionary_index_distance={}\n",
    "    dictionary_final={}\n",
    "    distance_newclusterhead=[]\n",
    "    jo =[]\n",
    "    list_clusters=[]\n",
    "    lo =[]\n",
    "    list_newclusterhead=[]\n",
    "    dictionary_intradistance={}\n",
    "    dictionary_newfinal={}\n",
    "    dictionary_index_newdistance={} \n",
    "    dictionary_newintradistance={}\n",
    "    dictionary_new_clusterhead={}\n",
    "    \n",
    "    #calculating te euclidean distance between  the random medoids and all the instances in the dataframe and creating a \n",
    "    # distance matrix.\n",
    "    \n",
    "    for i in range(len(effective_dataframe.values)):\n",
    "        row_dt=[]\n",
    "        for j in range(len(sample_kinstances.values)):\n",
    "            distance=(eucledian_distance(effective_dataframe.values[i],sample_kinstances.values[j]))\n",
    "            row_dt.append(distance)\n",
    "        distance_matrix.append(row_dt)\n",
    "    \n",
    "    #making a list of tuples in which the i is the index of the instance with minimum distance from the cluster head and the cluster id as cluster head.\n",
    "    for i in range(len(distance_matrix)):\n",
    "        distance=min(distance_matrix[i])\n",
    "        \n",
    "        cluster_head=distance_matrix[i].index(distance)\n",
    "        jo.append((i,cluster_head))\n",
    "\n",
    "        \n",
    "    #Traversing the list of tuples to finally store the cluster head id as the jkey and vale is the list of instances that belong to\n",
    "    # that particular cluster.\n",
    "    for tuplex in jo:\n",
    "        if tuplex[1] not in dictionary_final.keys():\n",
    "            dictionary_final[tuplex[1]]=[tuplex[0]]\n",
    "        else:\n",
    "            dictionary_final[tuplex[1]].append(tuplex[0])\n",
    "        \n",
    "    \n",
    "    #Finding the data points with minimum cost from all teh datapoints within the cluster and making them the\n",
    "    #new clusterhead.\n",
    "    for key,value in dictionary_final.items():\n",
    "        list_min=[]\n",
    "        for x in value:\n",
    "            intra_distance=0\n",
    "            for j in value:\n",
    "                intra_distance+=(eucledian_distance(effective_dataframe.iloc[x],effective_dataframe.iloc[j]))\n",
    "            list_min.append(intra_distance)\n",
    "        \n",
    "\n",
    "        min_value=min(list_min)\n",
    "        index_minvalue=list_min.index(min_value)\n",
    "        \n",
    "        dictionary_intradistance[key]=value[index_minvalue]\n",
    "        list_min=[]\n",
    "    \n",
    "    \n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    #Making a new dataframe of new cluster heads and then again finding the new distances between the new cluster heads and \n",
    "    #all teh datapounts to finally create a new cluster, same as done with the random medoids.\n",
    "    for i in dictionary_intradistance.keys():\n",
    "        new_clusterhead=(effective_dataframe.iloc[[dictionary_intradistance[i]]])\n",
    "        df=df.append(new_clusterhead)\n",
    "    print(df)\n",
    "    sample_kinstances=df\n",
    "    \n",
    "    for i in range(len(effective_dataframe.values)):\n",
    "        row_dt=[]\n",
    "        for j in range(len(df.values)):\n",
    "            distance=(eucledian_distance(effective_dataframe.values[i],df.values[j]))\n",
    "            row_dt.append(distance)\n",
    "        distance_newclusterhead.append(row_dt)\n",
    "        \n",
    "    \n",
    "       \n",
    "    for i in range(len(distance_newclusterhead)):\n",
    "        distance=min(distance_newclusterhead[i])\n",
    "        cluster_head=distance_newclusterhead[i].index(distance)\n",
    "        lo.append((i,cluster_head))\n",
    "\n",
    "    for tuplex in lo:\n",
    "        if tuplex[1] not in dictionary_newfinal.keys():\n",
    "            dictionary_newfinal[tuplex[1]]=[tuplex[0]]\n",
    "        else:\n",
    "            dictionary_newfinal[tuplex[1]].append(tuplex[0])\n",
    "                      \n",
    "        dictionary_conewfinal.update(dictionary_newfinal)\n",
    "    #print(dictionary_conewfinal)\n",
    "            \n",
    "    #checking if the new cluster formed and the prevoius one are same or not, if yes the loop of creatinf another cluster will \n",
    "    #terminate.\n",
    "    if dictionary_conewfinal==dictionary_final:\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "                         \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[12.006455050563105], [12.891326280204604], [14.071554253550621], [14.764596215786002], [13.72167839234648], [24.687686759851626], [13.762379908214715], [8.408591183797858], [13.835588786880885], [9.297658683095674], [8.408591183797858], [12.006455050563105], [18.582719067656793], [39.11151546777912], [39.900097978371676], [30.452163999657692], [9.935790114215726], [9.132019989018845], [13.218326366282335], [14.82855208482776], [37.47931806497865], [9.455568206088039], [21.570004970735596], [12.006455050563105], [40.8333376294366], [18.668207786865374], [12.939532008042063], [15.449380741659402], [16.513003090877174], [12.781133988881091], [18.668207786865374], [9.370139655184898], [12.226777609880417], [8.874811771382014], [15.782006838579571], [20.39918592579794], [9.272699809690561], [9.132019989018845], [11.827999198970229], [9.063479595980663], [19.636991101067], [8.831266597704161], [10.172794746110222], [9.278822744792542], [21.470538216686485], [18.655060251332785], [17.666600028319213], [22.453222220783637], [15.625639435491419], [8.408591183797858], [14.82855208482776], [10.163037180699945], [15.742041991036196], [11.287260392529445], [16.74020530902855], [8.408244736517359], [31.727716965144122]]\n",
      "1 [[16.39529728105802], [17.539656109723843], [13.635529062396937], [20.17405166070258], [14.554892572906182], [18.25033687412109], [22.150035517866648], [15.664914870399654], [19.370110346808413], [14.7396120097358], [13.635529062396937], [13.726537960027285], [10.953377852877088], [17.5488813159916], [15.579292328699243], [11.08422050990423], [19.3606992284156], [20.334255019011195], [16.598786313149365], [20.225006230602244], [13.523924682438562], [22.944232437903175], [14.7396120097358], [13.68489265359647], [22.315434776271065], [10.252491921727822], [17.464003916500566], [20.329176374191587], [16.42505305081324], [15.38682102968669], [15.664914870399654], [14.238913888180747], [15.664914870399654], [10.226687899765446], [12.758429617540012], [20.329176374191587], [13.824990095262104], [16.598786313149365], [10.226687899765446], [21.35297431375693], [16.44801294998909], [15.769964180587541], [20.74008985854425], [17.916473631616945], [14.7396120097358], [17.539656109723843], [16.42505305081324], [11.053208050997455], [14.892269307460385], [18.486334560456317], [15.537431060236145], [13.726537960027285], [17.512367857140088], [22.256696870394407], [17.599773860621255], [13.824990095262104], [14.554892572906182], [17.294990279317258], [13.435388656301928], [15.41982183792016], [11.768604653190067], [17.539656109723843], [11.180673183394482], [15.664914870399654], [11.180673183394482], [13.10920231719549], [13.824990095262104], [13.824990095262104], [14.7396120097358], [15.485594171388835], [16.598786313149365], [17.3462717327452], [19.33053337782606], [23.514695994927628]]\n",
      "{0: 0.2681306530811398, 1: 0.5896114763186323}\n",
      "0.42887106469988606 Average Width\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict_cc={}\n",
    "df_pk=effective_dataframe.copy(deep=True)\n",
    "\n",
    "# Creating a csv file for storing the cluster head alloted to the instances in the dataframe.\n",
    "for i,value in dictionary_conewfinal.items():\n",
    "    \n",
    "    for k in value:\n",
    "        dict_cc[k]=i\n",
    "        \n",
    "df_cluserhead=pd.DataFrame.from_dict(dict_cc,orient='index')\n",
    "\n",
    "df_clus=df_cluserhead.rename(columns={0:'CLusterhead'})\n",
    "\n",
    "ff=df_pk.join(df_clus)\n",
    "ff.to_csv('cluster_2.csv', sep=';', encoding='utf-8')\n",
    "\n",
    "\n",
    "remaining_list=[]\n",
    "list_totalpoits=[]\n",
    "list_sublists=[]\n",
    "dictioary_B_itradistace={}\n",
    "\n",
    "# This is used for finding the value of b when k=2, as we just have to find the distance between each point of the cluster and\n",
    "#the one it does not belong to.\n",
    "\n",
    "for key,value in dictionary_conewfinal.items():\n",
    "    for row_idex in value:\n",
    "        list_totalpoits.append(row_idex)\n",
    "\n",
    "# This is used for finding the value of b when k=3 and more, as we have to find the distance between each sublist of point of the cluster and\n",
    "#it does not belong to.\n",
    "for key,value in dictionary_conewfinal.items():\n",
    "    list_sublists.append(value)\n",
    "\n",
    "\n",
    "#For finding the value of a, in which find the average distance between each points and points within the cluster.\n",
    "for key,value in dictionary_conewfinal.items():\n",
    "    a_average=[]\n",
    "    for x in value:\n",
    "        list_min=[]\n",
    "        intra_distance=0\n",
    "        for j in value:\n",
    "            intra_distance=(eucledian_distance(effective_dataframe.iloc[x],effective_dataframe.iloc[j]))\n",
    "            list_min.append(intra_distance)\n",
    "        a_average.append(sum(list_min)/len(list_min))\n",
    "    dictionary_newintradistance[key]=a_average \n",
    "\n",
    "#Finding the value of b by by iterating the list of datapoints of the other clusters and then finding the minimum value of the two values of\n",
    "#average distance from all the datapoints of other clustrs\n",
    "if k == 2:\n",
    "    for key,value in dictionary_conewfinal.items():\n",
    "        a_average=[]\n",
    "        remaining_list=[i for i in list_totalpoits if i not in  value]\n",
    "\n",
    "        for x in value:\n",
    "\n",
    "            list_min=[]\n",
    "            intra_distance=0\n",
    "            for j in remaining_list:\n",
    "                intra_distance=(eucledian_distance(effective_dataframe.iloc[x],effective_dataframe.iloc[j]))\n",
    "                list_min.append(intra_distance)\n",
    "\n",
    "            a_average.append(sum(list_min)/len(list_min))\n",
    "        \n",
    "        dictioary_B_itradistace[key]=a_average \n",
    "   \n",
    "    #Using the values of a and b and calculating the average silhoutte width using the known formula of all the points within \n",
    "    #cluster. This will give us the average silhoutte width of each cluster and which is then stored in the dictionary\n",
    "    final={}        \n",
    "    for key in dictioary_B_itradistace.keys():\n",
    "        list_eachpoit_width=[]\n",
    "\n",
    "        for i,j in zip(dictionary_newintradistance[key],dictioary_B_itradistace[key]):\n",
    "\n",
    "            eachpointwidth=(j-i)/max(i,j)\n",
    "            list_eachpoit_width.append(eachpointwidth)\n",
    "        avg_width=(sum(list_eachpoit_width)/len(list_eachpoit_width))\n",
    "        final[key]=avg_width\n",
    "    print(final)\n",
    "    \n",
    "    #Calculating the average of all the silhoutte widths of each cluster to give a net width value.\n",
    "    ans=0\n",
    "    for key, value in final.items():\n",
    "        ans+=value\n",
    "    print(ans/len(final),\"Average Width\")   \n",
    "            \n",
    "    \n",
    "else:\n",
    "    for key,value in dictionary_conewfinal.items():\n",
    "\n",
    "        ll=[]\n",
    "        remaining_list=list_sublists\n",
    "        remaining_list=[i for i in list_sublists if i != value]\n",
    "        for x in value:\n",
    "            list_min=[]\n",
    "            intra_distance=0\n",
    "            a_average=[]\n",
    "            for j in remaining_list:\n",
    "                for t in j: \n",
    "                    intra_distance=(eucledian_distance(effective_dataframe.iloc[x],effective_dataframe.iloc[t]))\n",
    "                    list_min.append(intra_distance)\n",
    "                a_average.append(sum(list_min)/len(list_min))\n",
    "            ll.append(a_average)\n",
    "        dictioary_B_itradistace[key]=ll\n",
    "\n",
    "    dict_SS={}\n",
    "    \n",
    "     #Using the values of a and b and calculating the average silhoutte width using the known formula of all the points within \n",
    "    #cluster. This will give us the average silhoutte width of each cluster and which is then stored in the dictionary.\n",
    "    for key,value in dictioary_B_itradistace.items():\n",
    "        jlo=[]\n",
    "        print(key,value)\n",
    "        for value1 in value:\n",
    "            jlo.append(min(value1))\n",
    "\n",
    "        dict_SS[key]=jlo\n",
    "    final={}        \n",
    "    for key in dict_SS.keys():\n",
    "        list_eachpoit_width=[]\n",
    "\n",
    "        for i,j in zip(dictionary_newintradistance[key],dict_SS[key]):\n",
    "\n",
    "            eachpointwidth=(j-i)/max(i,j)\n",
    "            list_eachpoit_width.append(eachpointwidth)\n",
    "        avg_width=(sum(list_eachpoit_width)/len(list_eachpoit_width))\n",
    "        final[key]=avg_width\n",
    "    print(final)\n",
    "            \n",
    "\n",
    "    #Calculating the average of all the silhoutte widths of each cluster to give a net width value.\n",
    "    ans=0\n",
    "    for key, value in final.items():\n",
    "        ans+=value\n",
    "    print(ans/len(final),\"Average Width\")   \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     InpatientDays  ERVisits  OfficeVisits\n",
      "101              1         2            11\n",
      "4                8         2            19\n",
      "76              10         1             3\n",
      "     InpatientDays  ERVisits  OfficeVisits\n",
      "41               1         0             9\n",
      "112              2         2            22\n",
      "23               8         4             6\n",
      "     InpatientDays  ERVisits  OfficeVisits\n",
      "112              2         2            22\n",
      "15               0         0             8\n",
      "77               9         4             6\n",
      "    InpatientDays  ERVisits  OfficeVisits\n",
      "13              1         1            20\n",
      "15              0         0             8\n",
      "77              9         4             6\n",
      "    InpatientDays  ERVisits  OfficeVisits\n",
      "13              1         1            20\n",
      "86              1         0             7\n",
      "77              9         4             6\n",
      "    InpatientDays  ERVisits  OfficeVisits\n",
      "13              1         1            20\n",
      "86              1         0             7\n",
      "77              9         4             6\n"
     ]
    }
   ],
   "source": [
    "#Calculating cluters for k=3\n",
    "k=3\n",
    "sample_kinstances=effective_dataframe.sample(n=k,replace=False)\n",
    "\n",
    "\n",
    "dictionary_conewfinal={}\n",
    "for couter in range(100):\n",
    "    \n",
    "    distance_matrix=[]\n",
    "    dictionary_index_distance={}\n",
    "    dictionary_final={}\n",
    "    distance_newclusterhead=[]\n",
    "    jo =[]\n",
    "    list_clusters=[]\n",
    "    lo =[]\n",
    "    list_newclusterhead=[]\n",
    "    dictionary_intradistance={}\n",
    "    dictionary_newfinal={}\n",
    "    dictionary_index_newdistance={} \n",
    "    dictionary_newintradistance={}\n",
    "    dictionary_new_clusterhead={}\n",
    "    \n",
    "    #calculating te euclidean distance between  the random medoids and all the instances in the dataframe and creating a \n",
    "    # distance matrix.\n",
    "    \n",
    "    for i in range(len(effective_dataframe.values)):\n",
    "        row_dt=[]\n",
    "        for j in range(len(sample_kinstances.values)):\n",
    "            distance=(eucledian_distance(effective_dataframe.values[i],sample_kinstances.values[j]))\n",
    "            row_dt.append(distance)\n",
    "        distance_matrix.append(row_dt)\n",
    "    \n",
    "    #making a list of tuples in which the i is the index of the instance with minimum distance from the cluster head and the cluster id as cluster head.\n",
    "    for i in range(len(distance_matrix)):\n",
    "        distance=min(distance_matrix[i])\n",
    "        \n",
    "        cluster_head=distance_matrix[i].index(distance)\n",
    "        jo.append((i,cluster_head))\n",
    "\n",
    "        \n",
    "    #Traversing the list of tuples to finally store the cluster head id as the jkey and vale is the list of instances that belong to\n",
    "    # that particular cluster.\n",
    "    for tuplex in jo:\n",
    "        if tuplex[1] not in dictionary_final.keys():\n",
    "            dictionary_final[tuplex[1]]=[tuplex[0]]\n",
    "        else:\n",
    "            dictionary_final[tuplex[1]].append(tuplex[0])\n",
    "        \n",
    "    \n",
    "    #Finding the data points with minimum cost from all teh datapoints within the cluster and making them the\n",
    "    #new clusterhead.\n",
    "    for key,value in dictionary_final.items():\n",
    "        list_min=[]\n",
    "        for x in value:\n",
    "            intra_distance=0\n",
    "            for j in value:\n",
    "                intra_distance+=(eucledian_distance(effective_dataframe.iloc[x],effective_dataframe.iloc[j]))\n",
    "            list_min.append(intra_distance)\n",
    "        \n",
    "\n",
    "        min_value=min(list_min)\n",
    "        index_minvalue=list_min.index(min_value)\n",
    "        \n",
    "        dictionary_intradistance[key]=value[index_minvalue]\n",
    "        list_min=[]\n",
    "    \n",
    "    \n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    #Making a new dataframe of new cluster heads and then again finding the new distances between the new cluster heads and \n",
    "    #all teh datapounts to finally create a new cluster, same as done with the random medoids.\n",
    "    for i in dictionary_intradistance.keys():\n",
    "        new_clusterhead=(effective_dataframe.iloc[[dictionary_intradistance[i]]])\n",
    "        df=df.append(new_clusterhead)\n",
    "    print(df)\n",
    "    sample_kinstances=df\n",
    "    \n",
    "    for i in range(len(effective_dataframe.values)):\n",
    "        row_dt=[]\n",
    "        for j in range(len(df.values)):\n",
    "            distance=(eucledian_distance(effective_dataframe.values[i],df.values[j]))\n",
    "            row_dt.append(distance)\n",
    "        distance_newclusterhead.append(row_dt)\n",
    "        \n",
    "    \n",
    "       \n",
    "    for i in range(len(distance_newclusterhead)):\n",
    "        distance=min(distance_newclusterhead[i])\n",
    "        cluster_head=distance_newclusterhead[i].index(distance)\n",
    "        lo.append((i,cluster_head))\n",
    "\n",
    "    for tuplex in lo:\n",
    "        if tuplex[1] not in dictionary_newfinal.keys():\n",
    "            dictionary_newfinal[tuplex[1]]=[tuplex[0]]\n",
    "        else:\n",
    "            dictionary_newfinal[tuplex[1]].append(tuplex[0])\n",
    "                      \n",
    "        dictionary_conewfinal.update(dictionary_newfinal)\n",
    "    #print(dictionary_conewfinal)\n",
    "            \n",
    "    #checking if the new cluster formed and the prevoius one are same or not, if yes the loop of creatinf another cluster will \n",
    "    #terminate.\n",
    "    if dictionary_conewfinal==dictionary_final:\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "                         \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[11.260023845195153, 12.265964548002591], [12.20211151125715, 13.121851553111437], [14.218632649537188, 14.072646388600504], [14.757040160080116, 14.786520541878373], [13.153495655810167, 13.906881372883225], [24.646864375934644, 24.58274140333954], [13.360982373825562, 13.904388417585508], [7.449685663838789, 8.776946366051671], [13.184226520793484, 14.042655619079701], [9.12112115753356, 9.504216316451812], [7.449685663838789, 8.776946366051671], [11.260023845195153, 12.265964548002591], [19.17219269610277, 18.37969351813497], [39.255182435813, 38.85554506364241], [39.70714957725257, 39.77772196271145], [30.15005755722505, 30.402324779475006], [9.41121307468072, 10.19253978666566], [8.334773992444658, 9.451416840013723], [12.978098887625302, 13.328754108207509], [14.197180248579311, 15.017712751481803], [38.517399060892835, 36.9442412808412], [8.633015665142281, 9.777798808125297], [21.13828110797167, 21.62570892340398], [11.260023845195153, 12.265964548002591], [41.06795011099859, 40.54313602522315], [18.148976137886947, 18.77939581365589], [12.235113282185512, 13.174424142360001], [16.899354520927925, 16.398422304968193], [12.256170157154111, 12.97123789935014], [18.148976137886947, 18.77939581365589], [8.593218306418516, 9.698749471245664], [11.999981925588454, 12.36043263875377], [8.589618454285041, 9.114464235134593], [15.182430945103066, 15.950039331023312], [20.07765799760554, 20.443035144115665], [8.41561236557312, 9.602738215879105], [8.334773992444658, 9.451416840013723], [11.187734456447375, 12.06145866728142], [8.283207376338915, 9.378655349958386], [19.140396150243287, 19.731247944208093], [8.362671580162697, 9.099061742920439], [9.329397789411699, 10.4848801445955], [8.37990776396322, 9.618679119680836], [21.136578309522775, 21.493475593953562], [18.16305407351862, 18.757990715838414], [17.136078605085498, 17.791576551481594], [22.084681462265202, 22.478956559003528], [15.213979191415113, 15.739335681126928], [7.449685663838789, 8.776946366051671], [14.197180248579311, 15.017712751481803], [9.359184858344888, 10.465312955819392], [15.156517623116114, 15.905782837024503], [11.067569003396843, 11.438877524765601], [16.16972736181662, 16.88822955473914], [7.493884576128919, 8.7667705215303]]\n",
      "1 [[16.09219672833783, 15.520545426005112], [17.22298221150797, 16.67507333502792], [13.312656918362428, 13.128737219192105], [14.246855223022989, 13.87757898162302], [17.99702072129515, 16.993295178868685], [21.986712758750883, 20.309872550406155], [15.32020042929043, 15.078369073132759], [19.081468268807406, 18.25311363363915], [14.379661814730524, 14.309496312359682], [13.312656918362428, 13.128737219192105], [13.353686559100689, 13.448423651212577], [10.620084624981061, 10.874595473172043], [15.23777133830006, 14.973994822336081], [10.746808603544585, 11.01841934806279], [19.075768262162047, 18.22659613768461], [16.26848664678593, 15.86734336504585], [20.046244141543834, 18.495081005568075], [13.210189247473423, 12.978591280531205], [14.379661814730524, 14.309496312359682], [13.334119751209295, 13.30546863433406], [22.05650520523429, 20.956989916016397], [9.8143392935469, 10.723381976361607], [17.15044614415354, 16.578673873915346], [20.05196558787275, 19.11410147150106], [16.14422314081218, 15.445216187605956], [15.101297510387289, 14.50758452946714], [15.32020042929043, 15.078369073132759], [15.32020042929043, 15.078369073132759], [9.781796731839334, 10.716983171853892], [20.05196558787275, 19.11410147150106], [13.448965120191533, 13.562396381754244], [16.26848664678593, 15.86734336504585], [9.781796731839334, 10.716983171853892], [21.08373826724174, 20.071918968211452], [16.154771610646346, 15.539855203414348], [15.565719699874995, 14.521512799359163], [14.379661814730524, 14.309496312359682], [17.22298221150797, 16.67507333502792], [16.14422314081218, 15.445216187605956], [10.78599966105344, 10.957620020692369], [18.18253687734074, 17.50042861506191], [15.217043362717392, 14.830520421847734], [13.353686559100689, 13.448423651212577], [17.20784450616418, 16.595959032145718], [22.000520665054037, 20.877922582941572], [13.448965120191533, 13.562396381754244], [14.246855223022989, 13.87757898162302], [17.061245305923613, 15.999940342855151], [13.088218053602155, 13.379148330489016], [15.158004622619654, 14.42263736589993], [11.393186863554584, 11.731361079607568], [17.22298221150797, 16.67507333502792], [10.75167211547448, 11.477926003408909], [15.32020042929043, 15.078369073132759], [10.75167211547448, 11.477926003408909], [12.740707304606342, 12.953892681151745], [13.448965120191533, 13.562396381754244], [13.448965120191533, 13.562396381754244], [14.379661814730524, 14.309496312359682], [15.191565074714273, 14.650480281341737], [16.26848664678593, 15.86734336504585], [17.056229632229215, 16.337748995398535], [19.061233053017826, 18.117574576986073]]\n",
      "2 [[20.34684715944794, 17.78931215745726], [17.473527791957732, 12.743965533016425], [20.181671181120322, 13.259673766300004], [23.1925789534827, 20.675265230353276], [14.117969883585687, 11.102028799316678], [13.757372832817582, 15.00404162382102], [12.664564459487552, 11.564430376315876], [20.71997988161372, 15.269155671793891], [17.874409083421867, 13.38062517942006], [14.79069032452764, 11.295580777286855], [17.651237588390213, 15.187418026715692], [23.67667244109128, 20.572158313026936], [28.813200027219263, 31.001950943805827]]\n",
      "{0: 0.2684281299360881, 1: 0.6771210322965425, 2: 0.3303709335439089}\n",
      "0.42530669859217984 Average Width\n"
     ]
    }
   ],
   "source": [
    "dict_cc={}\n",
    "df_pk=effective_dataframe.copy(deep=True)\n",
    "\n",
    "# Creating a csv file for storing the cluster head alloted to the instances in the dataframe.\n",
    "for i,value in dictionary_conewfinal.items():\n",
    "    \n",
    "    for k in value:\n",
    "        dict_cc[k]=i\n",
    "        \n",
    "df_cluserhead=pd.DataFrame.from_dict(dict_cc,orient='index')\n",
    "\n",
    "df_clus=df_cluserhead.rename(columns={0:'CLusterhead'})\n",
    "\n",
    "ff=df_pk.join(df_clus)\n",
    "ff.to_csv('cluster_3.csv', sep=';', encoding='utf-8')\n",
    "\n",
    "\n",
    "remaining_list=[]\n",
    "list_totalpoits=[]\n",
    "list_sublists=[]\n",
    "dictioary_B_itradistace={}\n",
    "\n",
    "# This is used for finding the value of b when k=2, as we just have to find the distance between each point of the cluster and\n",
    "#the one it does not belong to.\n",
    "\n",
    "for key,value in dictionary_conewfinal.items():\n",
    "    for row_idex in value:\n",
    "        list_totalpoits.append(row_idex)\n",
    "\n",
    "# This is used for finding the value of b when k=3 and more, as we have to find the distance between each sublist of point of the cluster and\n",
    "#it does not belong to.\n",
    "for key,value in dictionary_conewfinal.items():\n",
    "    list_sublists.append(value)\n",
    "\n",
    "\n",
    "#For finding the value of a, in which find the average distance between each points and points within the cluster.\n",
    "for key,value in dictionary_conewfinal.items():\n",
    "    a_average=[]\n",
    "    for x in value:\n",
    "        list_min=[]\n",
    "        intra_distance=0\n",
    "        for j in value:\n",
    "            intra_distance=(eucledian_distance(effective_dataframe.iloc[x],effective_dataframe.iloc[j]))\n",
    "            list_min.append(intra_distance)\n",
    "        a_average.append(sum(list_min)/len(list_min))\n",
    "    dictionary_newintradistance[key]=a_average \n",
    "\n",
    "#Finding the value of b by by iterating the list of datapoints of the other clusters and then finding the minimum value of the two values of\n",
    "#average distance from all the datapoints of other clustrs\n",
    "if k == 2:\n",
    "    for key,value in dictionary_conewfinal.items():\n",
    "        a_average=[]\n",
    "        remaining_list=[i for i in list_totalpoits if i not in  value]\n",
    "\n",
    "        for x in value:\n",
    "\n",
    "            list_min=[]\n",
    "            intra_distance=0\n",
    "            for j in remaining_list:\n",
    "                intra_distance=(eucledian_distance(effective_dataframe.iloc[x],effective_dataframe.iloc[j]))\n",
    "                list_min.append(intra_distance)\n",
    "\n",
    "            a_average.append(sum(list_min)/len(list_min))\n",
    "        \n",
    "        dictioary_B_itradistace[key]=a_average \n",
    "   \n",
    "    #Using the values of a and b and calculating the average silhoutte width using the known formula of all the points within \n",
    "    #cluster. This will give us the average silhoutte width of each cluster and which is then stored in the dictionary\n",
    "    final={}        \n",
    "    for key in dictioary_B_itradistace.keys():\n",
    "        list_eachpoit_width=[]\n",
    "\n",
    "        for i,j in zip(dictionary_newintradistance[key],dictioary_B_itradistace[key]):\n",
    "\n",
    "            eachpointwidth=(j-i)/max(i,j)\n",
    "            list_eachpoit_width.append(eachpointwidth)\n",
    "        avg_width=(sum(list_eachpoit_width)/len(list_eachpoit_width))\n",
    "        final[key]=avg_width\n",
    "    print(final)\n",
    "    \n",
    "    #Calculating the average of all the silhoutte widths of each cluster to give a net width value.\n",
    "    ans=0\n",
    "    for key, value in final.items():\n",
    "        ans+=value\n",
    "    print(ans/len(final),\"Average Width\")   \n",
    "            \n",
    "else:\n",
    "    for key,value in dictionary_conewfinal.items():\n",
    "\n",
    "        ll=[]\n",
    "        remaining_list=list_sublists\n",
    "        remaining_list=[i for i in list_sublists if i != value]\n",
    "        for x in value:\n",
    "            list_min=[]\n",
    "            intra_distance=0\n",
    "            a_average=[]\n",
    "            for j in remaining_list:\n",
    "                for t in j: \n",
    "                    intra_distance=(eucledian_distance(effective_dataframe.iloc[x],effective_dataframe.iloc[t]))\n",
    "                    list_min.append(intra_distance)\n",
    "                a_average.append(sum(list_min)/len(list_min))\n",
    "            ll.append(a_average)\n",
    "        dictioary_B_itradistace[key]=ll\n",
    "\n",
    "    dict_SS={}\n",
    "    \n",
    "     #Using the values of a and b and calculating the average silhoutte width using the known formula of all the points within \n",
    "    #cluster. This will give us the average silhoutte width of each cluster and which is then stored in the dictionary.\n",
    "    for key,value in dictioary_B_itradistace.items():\n",
    "        jlo=[]\n",
    "        print(key,value)\n",
    "        for value1 in value:\n",
    "            jlo.append(min(value1))\n",
    "\n",
    "        dict_SS[key]=jlo\n",
    "    final={}        \n",
    "    for key in dict_SS.keys():\n",
    "        list_eachpoit_width=[]\n",
    "\n",
    "        for i,j in zip(dictionary_newintradistance[key],dict_SS[key]):\n",
    "\n",
    "            eachpointwidth=(j-i)/max(i,j)\n",
    "            list_eachpoit_width.append(eachpointwidth)\n",
    "        avg_width=(sum(list_eachpoit_width)/len(list_eachpoit_width))\n",
    "        final[key]=avg_width\n",
    "    print(final)\n",
    "    \n",
    "    #Calculating the average of all the silhoutte widths of each cluster to give a net width value.\n",
    "    ans=0\n",
    "    for key, value in final.items():\n",
    "        ans+=value\n",
    "    print(ans/len(final),\"Average Width\")   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
